{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbjN-8O3sp9I"
      },
      "source": [
        "# Week 3: PyTorch, Logistic Regression and MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd7_qFa6sp9I"
      },
      "source": [
        "- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n",
        "- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n",
        "- We will use simple linear model and multi-layer perceptron (MLP) in this class\n",
        "\n",
        "If you have any questions, feel free to ask\n",
        "- For additional questions, post questions in classum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_6tgh_lsp9I"
      },
      "source": [
        "## Why PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMwIjuVvsp9J"
      },
      "source": [
        "- Intuitive and concise code\n",
        "- Define by Run method (Tensorflow is Define and Run method)\n",
        "- High compatibility with Numpy (almost one-to-one mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O3b-lLfsp9J"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AofEmIygsp9J"
      },
      "source": [
        "## 0. Prelim: Load packages & GPU setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fia9Dz_Osp9J",
        "outputId": "7517a2b3-ca66-42d9-bdac-0ca048a9dedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 19 01:59:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0              30W /  70W |    121MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# visualize current GPU usages in your server\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "pTj8gTCqsp9K"
      },
      "outputs": [],
      "source": [
        "# set gpu by number\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXLR6ixYsp9L",
        "outputId": "44ecb581-bf8b-455e-88ba-f876379310e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "# load packages\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk1UF7XYsp9L",
        "outputId": "0c62be68-6a7d-496c-d9ee-2bbb9c141726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "# print the version of PyTorch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vUJG0Ofsp9L"
      },
      "source": [
        "## 1. PyTorch Tensors and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG5rTO8tsp9L"
      },
      "source": [
        "PyTorch use **tensor**: the basic data structure in PyTorch.\\\n",
        "**Tensor: n-dimensional array + GPU calculation is supported**\\\n",
        "**Almost the same with Numpy array**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0luwTVGsp9L"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPaY0_2bsp9M"
      },
      "source": [
        "### PyTorch Tensors and Numpy shares almost identical grammer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ye-IRxsp9M"
      },
      "source": [
        "\n",
        "**We will show some examples of:**\n",
        "- Same operation with identical grammer\n",
        "- Same operation with different grammer\n",
        "- Different operation with same grammer\n",
        "\n",
        "**We will not handle all examples in this class :(**\n",
        "- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5RrHkDdsp9O"
      },
      "source": [
        "**First! Define Numpy array and PyTorch tensor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT6LsNonsp9O",
        "outputId": "fa5175b8-b1fd-48b5-c554-ab466ba34ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4]\n",
            "[5 6 7 8]\n",
            "tensor([1, 2, 3, 4])\n",
            "tensor([5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "np_array_1 = np.array([1, 2, 3, 4])\n",
        "np_array_2 = np.array([5, 6, 7, 8])\n",
        "torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n",
        "torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n",
        "\n",
        "print (np_array_1)\n",
        "print (np_array_2)\n",
        "print (torch_tensor_1)\n",
        "print (torch_tensor_2)\n",
        "\n",
        "# tensor is better than numpy array (for GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyb-3ySEsp9O"
      },
      "source": [
        "**1) Same operations with identical grammer**\n",
        "\n",
        "Example) Get the shape of the tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVKGdRwNsp9P",
        "outputId": "13145261-1297-445a-9ac0-3bd12950431b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,)\n",
            "torch.Size([4])\n",
            "torch.Size([4])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "print (np_array_1.shape)\n",
        "\n",
        "# torch\n",
        "print (torch_tensor_1.shape)\n",
        "print (torch_tensor_1.size()) # size() and shape operation is identical in torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ph6yZ4Nsp9P"
      },
      "source": [
        "**2) Same operations with different grammer**\n",
        "\n",
        "Example 1) Concatenate two tensors\n",
        "- numpy use `np.concatenate`\n",
        "- torch use `torch.cat`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6AZYswBsp9P",
        "outputId": "f890d7dd-d5ce-467b-b863-1c336a53d082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[1 2 3 4 5 6 7 8]\n",
            "----torch----\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_concate = np.concatenate([np_array_1, np_array_2], axis=0)\n",
        "print ('----numpy----')\n",
        "print (np_concate)\n",
        "\n",
        "# torch\n",
        "torch_concate= torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n",
        "print ('----torch----')\n",
        "print (torch_concate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_baPgLasp9Q"
      },
      "source": [
        "Example 2) reshape the tensor shape\n",
        "- numpy use `X.reshape`\n",
        "- torch use `X.view`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBMJhl6tsp9Q",
        "outputId": "de604667-6c67-4985-aace-9a25347c57c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [7 8]]\n",
            "(4, 2)\n",
            "----torch----\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n",
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "# numpy\n",
        "np_reshaped = np_concate.reshape(4, 2)\n",
        "print ('----numpy----')\n",
        "print (np_reshaped)\n",
        "print (np_reshaped.shape)\n",
        "\n",
        "# torch\n",
        "torch_reshaped = torch_concate.view(4, 2)\n",
        "print ('----torch----')\n",
        "print (torch_reshaped)\n",
        "print (torch_reshaped.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nQopYNcsp9Q"
      },
      "source": [
        "**3) Different operations with same grammer (Confusing operations)**\n",
        "\n",
        "Example) manipulation tensors\n",
        "- Same grammer `repeat`  has different operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL05Z6GYsp9R",
        "outputId": "2eb5cb72-cce3-4b5b-fdc8-8e889ced8029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----numpy----\n",
            "[1 2 3]\n",
            "[1 1 2 2 3 3]\n",
            "----torch----\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3, 1, 2, 3])\n",
            "----obtain the same result-----\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "tensor([[1, 1],\n",
            "        [2, 2],\n",
            "        [3, 3]])\n",
            "tensor([1, 1, 2, 2, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2, 3])\n",
        "x_repeat = x.repeat(2)\n",
        "\n",
        "print ('----numpy----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(2)\n",
        "\n",
        "print ('----torch----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n",
        "print('----obtain the same result-----')\n",
        "x_repeat = x.view(3, 1)\n",
        "print (x_repeat)\n",
        "\n",
        "x_repeat = x_repeat.repeat(1, 2)\n",
        "print (x_repeat)\n",
        "\n",
        "x_repeat = x_repeat.view(-1)\n",
        "print (x_repeat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQP6FnKbsp9R",
        "outputId": "73b480d2-e348-4961-f68a-a5ee3bb00e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n"
          ]
        }
      ],
      "source": [
        "# similar manipulation operation: stack & repeat\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(4)\n",
        "x_stack = torch.stack([x, x, x, x])\n",
        "\n",
        "print (x_repeat)\n",
        "print (x_stack)\n",
        "print (x_repeat.view(4, 3)) # reshape x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5eWKE4Nsp9R"
      },
      "source": [
        "## 2. Tensor operations under GPU utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXgOePsysp9R"
      },
      "source": [
        "Deep learning frameworks utilize GPUs to accelarate computations.\n",
        "\n",
        "In this section, we will learn **how to utilize GPU** in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEnKzXeIsp9S",
        "outputId": "2f933eb5-5f23-4120-e320-5a0e4a471ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())  # Is GPU accessible?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "v4QF2qY3sp9S"
      },
      "outputs": [],
      "source": [
        "a = torch.ones(3) # create tensor\n",
        "b = torch.randn(100, 50, 3) # creat tensor, random number of the tensor, 100 rows 50 columns, 3 layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVxUVMzWsp9S",
        "outputId": "60603b74-3aa6-4c01-a527-a7a244141dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Sa9qkmausp9S"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ2pfjr6sp9T",
        "outputId": "73296f53-a4c8-4bac-c5d2-2c573d401cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "YBmLLHZ5sp9U"
      },
      "outputs": [],
      "source": [
        "# upload a and b to GPU\n",
        "a = a.to('cuda')\n",
        "b = b.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynnrZrqTsp9U",
        "outputId": "d0480939-9284-46a0-b08a-335fc175c34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "VhoePABXsp9U"
      },
      "outputs": [],
      "source": [
        "c = a + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLvhKI2Dsp9U",
        "outputId": "0be30e5b-25bb-490c-fed9-36cee8407a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "7cu4nPxrsp9V"
      },
      "outputs": [],
      "source": [
        "c = c.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9zTgtkjsp9V",
        "outputId": "b3cae546-a572-4c0c-f16f-a5e2fdc97ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(c.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd96DeWesp9V"
      },
      "source": [
        "## 3. Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffTzyxGJsp9W"
      },
      "source": [
        "Central to all neural networks in PyTorch is the `autograd` package.\n",
        "\n",
        "The `autograd` package provides automatic differentiation for all operations on Tensors.\n",
        "\n",
        "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQFoPjiqsp9W"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXurRLYvsp9W",
        "outputId": "75e66544-6e2e-447d-b6e1-3d5223edec56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPVaCg9Csp9W",
        "outputId": "d4dfc508-6bfc-459a-d0ce-7d8cbd57356f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "y = x + 2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG5bWmCXsp9W",
        "outputId": "1647b06f-118e-4c1e-ec53-68391efd48be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KeFRqU-sp9X",
        "outputId": "51712031-d9a2-4945-a30d-5c7b309a845f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "out = z.mean()\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "vkGgBWjtsp9X"
      },
      "outputs": [],
      "source": [
        "y.retain_grad()\n",
        "z.retain_grad()\n",
        "out.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRbw5HOsp9X"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1JyMWTbaU6ktJAHx2XqiU7s4tId-cxiLF)\n",
        "![picture](https://drive.google.com/uc?id=17j-aNqj1yjZfVPCKZJRt6YVZ-7usf5PH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzKtqRSIsp9X",
        "outputId": "5fcfaced-8652-4491-dce9-8278c089044e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ]
        }
      ],
      "source": [
        "print(z.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM28F_Ousp9Y"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1jPfdq6piSkkwZ21nX7kIBa-xGJE6uPBu)\n",
        "![picture](https://drive.google.com/uc?id=1NN0kpdvRRP9NwguXJHnU3u8VikMFUKw2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dts8XdHfsp9Y",
        "outputId": "d13bdd14-4f0f-43e6-e028-b3cf01abaa7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kBM2Emesp9Y"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1HllHu2CxuNFX8mc6QdQEEtnXJ3Rvo6TE)\n",
        "![picture](https://drive.google.com/uc?id=1jWJPOXVLG6mdUyDSklocNWPVa9Rg62K3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PN7HmPysp9Y",
        "outputId": "85c7d124-7f4f-4a54-8419-3df11490cff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTnY5Phpsp9Y"
      },
      "source": [
        "### Efficient inference (testing) with torch.no_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kj0c60Hsp9Y"
      },
      "source": [
        "To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n",
        "\n",
        "Situation: when **gradient calculation is not required** e.g., inference\\\n",
        "Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "NqOULboAsp9Y"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    x = torch.ones(2, 2, requires_grad=True)\n",
        "    y = x + 2\n",
        "    z = y * y * 3\n",
        "    out = z.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxw9FVOBsp9Z",
        "outputId": "e8c6a456-df74-483c-99f6-d0a41f8b81dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "aTeg9iG_sp9Z"
      },
      "outputs": [],
      "source": [
        "#out.backward() ## ERROR!!!!: we used torch.no_grad()!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nje-BGjesp9Z"
      },
      "source": [
        "## 4. nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiVnymh6sp9Z"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXR5jfpqsp9Z"
      },
      "source": [
        "### Using pre-defined modules (subset of models) in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypn-7P5usp9a",
        "outputId": "51b99acf-81cd-428b-f2d0-03b82e506302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "\n",
        "print (X)\n",
        "print (X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "_ad-ZLk5sp9a"
      },
      "outputs": [],
      "source": [
        "# input dim 3, output dim 1\n",
        "linear_fn = nn.Linear(3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIAeq3f-sp9a",
        "outputId": "6b7551b8-fa2e-4db2-9fa7-b4cb8231165a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=3, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "linear_fn  # WX + b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_fn.weight"
      ],
      "metadata": {
        "id": "-CJ8KXKjFJqG",
        "outputId": "af0dac02-4ad1-4df5-857c-d38be3158d93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0701, -0.5702, -0.1513]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_fn.bias"
      ],
      "metadata": {
        "id": "ve802dLrFQMT",
        "outputId": "08606ec7-bafc-4bda-cec8-54200c5a2dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.1158], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smbL2japsp9a",
        "outputId": "406de546-6ba4-49a6-e061-31d637fc7d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5486],\n",
            "        [-3.9234]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([2, 1])\n"
          ]
        }
      ],
      "source": [
        "Y = linear_fn(X)\n",
        "print(Y)\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSlHALX1sp9b",
        "outputId": "85ae9cc0-ecf7-41de-839f-d9ec147673b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-5.4720, grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "Y = Y.sum()\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvztL-YIsp9b"
      },
      "source": [
        "You can use other types of `nn.Module` in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "6AJekGzfsp9b"
      },
      "outputs": [],
      "source": [
        "nn.Conv2d\n",
        "nn.RNNCell\n",
        "nn.LSTMCell\n",
        "nn.GRUCell\n",
        "nn.Transformer;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlf9096Hsp9b"
      },
      "source": [
        "### How can we design a customized model (neural network)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "UJgtdOYrsp9c"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x) # Activation function\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "# 10 classification -> output dim will be 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr-1kleXsp9c"
      },
      "source": [
        "**What is activation function?**\n",
        "- They make non-linearity for deep neural networks\n",
        "- Therefore, deep neural networks can approximate complex functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "W_wSvJWmsp9c"
      },
      "outputs": [],
      "source": [
        "nn.Sigmoid\n",
        "nn.ReLU\n",
        "nn.LeakyReLU\n",
        "nn.Tanh;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smL1Be1Zsp9d"
      },
      "source": [
        "## 5. MNIST classification with PyTorch (Logistic regression & MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvSHOjDTsp9e"
      },
      "source": [
        "### What is MNIST & How to do multi-class classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy9gJi_hsp9e"
      },
      "source": [
        "The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "\n",
        "Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n",
        "\n",
        "Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq29uTPusp9e"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr5dJKxOsp9e"
      },
      "source": [
        "### Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "AEssd29Vsp9e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tcrRyzSsp9f"
      },
      "source": [
        "### Load datasets for training & testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "wZmTjH_3sp9f"
      },
      "outputs": [],
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "# mini batch size -> 128 examples\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of examples in the training dataset: {len(train_loader.dataset)}\")\n",
        "print(f\"Number of examples in the test dataset: {len(test_loader.dataset)}\")"
      ],
      "metadata": {
        "id": "f_Yp9RsmG8JA",
        "outputId": "b96ca7d3-2084-47d3-ba70-c6c7618fe8dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in the training dataset: 60000\n",
            "Number of examples in the test dataset: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCGo8Y1Tsp9f"
      },
      "source": [
        "### Define model (we will use one layer classifier first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "GIxpsDbZsp9g"
      },
      "outputs": [],
      "source": [
        "# Define model class\n",
        "# This model has one hidden layer\n",
        "class Multinomial_logistic_regression(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Multinomial_logistic_regression, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc(x) # fully connected layer\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "aAJBK_1ksp9g"
      },
      "outputs": [],
      "source": [
        "# Generate model\n",
        "model = Multinomial_logistic_regression(784, 10)  # init(784, 10)\n",
        "# input dim: 784  / output dim: 10\n",
        "# 28 * 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eCAztzrsp9g",
        "outputId": "d0b8fc17-172a-47ee-d79a-2b4bb7dff299"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Multinomial_logistic_regression(\n",
              "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "gfQW99qHsp9h"
      },
      "outputs": [],
      "source": [
        "# Upload model to GPU\n",
        "model = model.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDf5serrsp9h"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4vBdxgxsp9h"
      },
      "source": [
        "Optimization is about finding the best solution (model parameter) that fits the given dataset!\n",
        "\n",
        "PyTorch optimizer is about **which optimization methods to use for training**\n",
        "\n",
        "We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "EOKbqVsOsp9h"
      },
      "outputs": [],
      "source": [
        "# Optimizer define\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# toptimizer = orch.optim.Adam(model.parameters(), lr=0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo1HbOMusp9h"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-DG5f50sp9i"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjwUv6E_sp9i",
        "outputId": "1a385a67-553c-4bbc-c9d5-10229687cf6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.1202\n",
            "Epoch [1/10], Step [200/469], Loss: 0.1144\n",
            "Epoch [1/10], Step [300/469], Loss: 0.1410\n",
            "Epoch [1/10], Step [400/469], Loss: 0.1493\n",
            "Epoch [2/10], Step [100/469], Loss: 0.1228\n",
            "Epoch [2/10], Step [200/469], Loss: 0.1483\n",
            "Epoch [2/10], Step [300/469], Loss: 0.0958\n",
            "Epoch [2/10], Step [400/469], Loss: 0.1497\n",
            "Epoch [3/10], Step [100/469], Loss: 0.1085\n",
            "Epoch [3/10], Step [200/469], Loss: 0.1016\n",
            "Epoch [3/10], Step [300/469], Loss: 0.0867\n",
            "Epoch [3/10], Step [400/469], Loss: 0.1686\n",
            "Epoch [4/10], Step [100/469], Loss: 0.1829\n",
            "Epoch [4/10], Step [200/469], Loss: 0.0913\n",
            "Epoch [4/10], Step [300/469], Loss: 0.1649\n",
            "Epoch [4/10], Step [400/469], Loss: 0.1761\n",
            "Epoch [5/10], Step [100/469], Loss: 0.1921\n",
            "Epoch [5/10], Step [200/469], Loss: 0.1132\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1455\n",
            "Epoch [5/10], Step [400/469], Loss: 0.2137\n",
            "Epoch [6/10], Step [100/469], Loss: 0.1677\n",
            "Epoch [6/10], Step [200/469], Loss: 0.1745\n",
            "Epoch [6/10], Step [300/469], Loss: 0.1284\n",
            "Epoch [6/10], Step [400/469], Loss: 0.1671\n",
            "Epoch [7/10], Step [100/469], Loss: 0.1133\n",
            "Epoch [7/10], Step [200/469], Loss: 0.0673\n",
            "Epoch [7/10], Step [300/469], Loss: 0.1242\n",
            "Epoch [7/10], Step [400/469], Loss: 0.1317\n",
            "Epoch [8/10], Step [100/469], Loss: 0.1707\n",
            "Epoch [8/10], Step [200/469], Loss: 0.1074\n",
            "Epoch [8/10], Step [300/469], Loss: 0.0846\n",
            "Epoch [8/10], Step [400/469], Loss: 0.0902\n",
            "Epoch [9/10], Step [100/469], Loss: 0.1323\n",
            "Epoch [9/10], Step [200/469], Loss: 0.0566\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1231\n",
            "Epoch [9/10], Step [400/469], Loss: 0.1025\n",
            "Epoch [10/10], Step [100/469], Loss: 0.0980\n",
            "Epoch [10/10], Step [200/469], Loss: 0.1808\n",
            "Epoch [10/10], Step [300/469], Loss: 0.0847\n",
            "Epoch [10/10], Step [400/469], Loss: 0.0480\n"
          ]
        }
      ],
      "source": [
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "# 1 epoch -> 모든 train_data\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (cross entropy loss) with ground truth & prediction value\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRWIix5Ysp9i"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5MLTXr6sp9j",
        "outputId": "bfe16500-839e-44ce-d472-7b6ab2a7161b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels.size: <built-in method size of Tensor object at 0x78d1d2b270b0>, labels.size(0): 128, len(labels): 128\n",
            "Accuracy of the network on the 10000 test images: 95.69 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classification -> get the label prediction of top 1\n",
        "        if correct == 0 :\n",
        "          print(f\"labels.size: {labels.size}, labels.size(0): {labels.size(0)}, len(labels): {len(labels)}\")\n",
        "          # labels.size(0) : 128\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u3eWP6Ysp9j"
      },
      "source": [
        "### New model: MLP (multi-layer-perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iubO05oLsp9j"
      },
      "source": [
        "Previous model used multinomial logistic regression (one linear layer)\\\n",
        "What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "P8HMCVbtsp9j"
      },
      "outputs": [],
      "source": [
        "# New model with multi layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()  # sigmoid activation function (you can customize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnhBSqrgsp9k",
        "outputId": "21e5a5a9-dd95-40a2-9288-ed33add29469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 2.2643\n",
            "Epoch [1/10], Step [200/469], Loss: 1.8202\n",
            "Epoch [1/10], Step [300/469], Loss: 1.1423\n",
            "Epoch [1/10], Step [400/469], Loss: 0.7594\n",
            "Epoch [2/10], Step [100/469], Loss: 0.4403\n",
            "Epoch [2/10], Step [200/469], Loss: 0.4306\n",
            "Epoch [2/10], Step [300/469], Loss: 0.3986\n",
            "Epoch [2/10], Step [400/469], Loss: 0.4158\n",
            "Epoch [3/10], Step [100/469], Loss: 0.2876\n",
            "Epoch [3/10], Step [200/469], Loss: 0.3880\n",
            "Epoch [3/10], Step [300/469], Loss: 0.2510\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2686\n",
            "Epoch [4/10], Step [100/469], Loss: 0.2597\n",
            "Epoch [4/10], Step [200/469], Loss: 0.2818\n",
            "Epoch [4/10], Step [300/469], Loss: 0.3433\n",
            "Epoch [4/10], Step [400/469], Loss: 0.2757\n",
            "Epoch [5/10], Step [100/469], Loss: 0.1329\n",
            "Epoch [5/10], Step [200/469], Loss: 0.2267\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1956\n",
            "Epoch [5/10], Step [400/469], Loss: 0.2292\n",
            "Epoch [6/10], Step [100/469], Loss: 0.2371\n",
            "Epoch [6/10], Step [200/469], Loss: 0.1794\n",
            "Epoch [6/10], Step [300/469], Loss: 0.2723\n",
            "Epoch [6/10], Step [400/469], Loss: 0.1824\n",
            "Epoch [7/10], Step [100/469], Loss: 0.3002\n",
            "Epoch [7/10], Step [200/469], Loss: 0.1822\n",
            "Epoch [7/10], Step [300/469], Loss: 0.2356\n",
            "Epoch [7/10], Step [400/469], Loss: 0.1115\n",
            "Epoch [8/10], Step [100/469], Loss: 0.1981\n",
            "Epoch [8/10], Step [200/469], Loss: 0.1858\n",
            "Epoch [8/10], Step [300/469], Loss: 0.1255\n",
            "Epoch [8/10], Step [400/469], Loss: 0.1675\n",
            "Epoch [9/10], Step [100/469], Loss: 0.1903\n",
            "Epoch [9/10], Step [200/469], Loss: 0.2257\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1937\n",
            "Epoch [9/10], Step [400/469], Loss: 0.1079\n",
            "Epoch [10/10], Step [100/469], Loss: 0.2151\n",
            "Epoch [10/10], Step [200/469], Loss: 0.0872\n",
            "Epoch [10/10], Step [300/469], Loss: 0.1162\n",
            "Epoch [10/10], Step [400/469], Loss: 0.1319\n"
          ]
        }
      ],
      "source": [
        "# Generate model\n",
        "model = NeuralNet(784, 20, 10)  # init(784, 20, 10)\n",
        "# Cf> hidden_size : hyper parameter\n",
        "\n",
        "# input dim: 784  / hidden dim: 20  / output dim: 10\n",
        "\n",
        "# Upload model to GPU\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (cross entropy loss) with ground truth & prediction value\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqzS5I06sp9k",
        "outputId": "c9897f5b-3b81-4f48-b75f-9d72b7eb7bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 95.15 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0 # how many predictions are correct\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classification -> get the label prediction of top 1\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jAvwUq1sp9l"
      },
      "source": [
        "### Change the following options to obtain better accuracy!! (try it by your-self)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWjgPRMzsp9l"
      },
      "source": [
        "#### (1) Model configurations:\n",
        "- size of hidden layer units\n",
        "- number of layers\n",
        "- type of activation function (e.g., relu, tanh, softplus etc.)\n",
        "\n",
        "#### (2) Optimization configurations\n",
        "- learning rate\n",
        "- epoch\n",
        "- type of optimizer\n",
        "- momentem hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two 2D tensors\n",
        "tensor1 = torch.tensor([[4]])\n",
        "tensor2 = torch.tensor([[3]])\n",
        "\n",
        "# Concatenate along axis=0 (row-wise)\n",
        "result = torch.cat((tensor1, tensor2), dim=0)\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "mN8PeqNxIygb",
        "outputId": "fee87c4e-d4d8-45fc-e66b-d1ad0946122a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4],\n",
            "        [3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.size()"
      ],
      "metadata": {
        "id": "JYVt7RKiI6g5",
        "outputId": "1671235a-09d3-4506-9e15-319fd71cfdeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.size(0)"
      ],
      "metadata": {
        "id": "j5tr_tRiI8TL",
        "outputId": "24343f53-6636-4589-ff5c-b684979146a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get one batch of data from the train_loader\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Shape of images: {images.shape}\")\n",
        "    print(f\"Shape of labels: {labels.shape}\")\n",
        "    break  # Break after the first batch, since we just want to see the shape"
      ],
      "metadata": {
        "id": "kV9fzVInJ3JD",
        "outputId": "fa109e86-c1e3-4248-d72b-f8c996c921db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images: torch.Size([128, 1, 28, 28])\n",
            "Shape of labels: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rd1i2urS9wDG"
      },
      "execution_count": 142,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}